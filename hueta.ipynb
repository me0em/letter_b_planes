{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ee7c4f",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–±—É–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é üí©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6251076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75e6fe",
   "metadata": {},
   "source": [
    "#### üêò <i><span style=\"color: #52C594\">import local stuff</span></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d89360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CNNClassifier\n",
    "from utils import PlaneSet, build_dataset\n",
    "from utils import configurate_xy_tensors  # wrap cuda and types stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c5408",
   "metadata": {},
   "source": [
    "#### Wrap a training loop in fn\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ead414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epoch_num, train, optimizer, distance):\n",
    "    loss_dict = {}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss_accumulator = []\n",
    "\n",
    "        for ind, (x, y) in enumerate(train):\n",
    "            x, y = configurate_xy_tensors(x, y)\n",
    "            y_hat = model(x)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = distance(y_hat, y)\n",
    "            diff = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_accumulator.append(diff)\n",
    "            \n",
    "        loss_dict[epoch] = np.mean(loss_accumulator)\n",
    "    \n",
    "    return model, loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98531582",
   "metadata": {},
   "source": [
    "#### Wrap a testing loop in fn\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997d7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test):\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in test:\n",
    "        x, y = configurate_xy_tensors(x, y)\n",
    "        y_hat = model.predict(x)\n",
    "        outputs = (y_hat>0.5).to(torch.float32)\n",
    "        correct += (outputs == y).float().sum()\n",
    "        \n",
    "        return correct / len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c555829",
   "metadata": {},
   "source": [
    "#### Run one experiment as function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d18ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(augmentation_compose, ModelClass,\n",
    "                   distance, num_epochs, df, images_path):\n",
    "    model = ModelClass()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    train_df = df[msk]\n",
    "    test_df = df[~msk]\n",
    "    \n",
    "    train = build_dataset(train_df, images_path, augmentation_compose)\n",
    "    test = build_dataset(test_df, images_path, None)\n",
    "    train = DataLoader(train, batch_size=100, shuffle=True)\n",
    "    test  = DataLoader(test, batch_size=100, shuffle=True)\n",
    "    \n",
    "    model, loss_dict = fit(model, num_epochs, train, optimizer, distance)\n",
    "    accuracy = predict(model, test)\n",
    "    \n",
    "    return {augmentation_compose: (loss_dict, accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04e289",
   "metadata": {},
   "source": [
    "#### Run all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a067b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance =  nn.BCELoss()\n",
    "num_epochs = 30\n",
    "\n",
    "csv_path = \"../train.csv\"\n",
    "images_path = \"../avia-train/\"\n",
    "\n",
    "with open(csv_path, \"r\") as file:\n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "# AUGMENTATION LIST HERE:\n",
    "augmentations = [\n",
    "    None,\n",
    "    torchvision.transforms.Compose([]),\n",
    "    torchvision.transforms.Compose([]),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for aug in aug_list:\n",
    "    experiment_result = run_experiment(\n",
    "        aug, CNNClassifier, distance,\n",
    "        num_epochs, data, images_path\n",
    "    )\n",
    "    \n",
    "    results.update(experiment_result)\n",
    "\n",
    "dump_name = \"result_\" + str(round(np.random.rand()*1e10))\n",
    "with open(dump_name, \"wb\") as bfile:\n",
    "    pickle.dump(results, bfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05467ead-fc49-4544-8506-c30f0cc3e836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2036, 0.2018, 0.2018],\n",
       "        [0.9497, 0.6666, 0.9811],\n",
       "        [0.0874, 0.0041, 0.1088]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([3, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d499e4c-2617-494e-9ad3-6595dd311c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2018, 0.2018, 0.2036],\n",
       "        [0.9811, 0.6666, 0.9497],\n",
       "        [0.1088, 0.0041, 0.0874]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013819c-2aab-4038-ad06-53702b7eb2c9",
   "metadata": {},
   "source": [
    "1 —à–∞–≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944a109-72df-4d7d-a8d7-6f24015a278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop\n",
    "resize\n",
    "contrast\n",
    "...\n",
    "\n",
    "20 —à—Ç—É–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1410219-d543-4407-a069-ef8f3da79241",
   "metadata": {},
   "source": [
    "2 —à–∞–≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cdcb05-b3f3-4f43-bf60-9cd27310606a",
   "metadata": {},
   "source": [
    "—Å–æ–±—Ä–∞—Ç—å –≤—Å–µ –∫–æ–º–±–∏–Ω –∫–æ–º–± –ø–æ —Ç—Ä–∏ —à—Ç—É–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da590b-2d60-46f0-800b-0d3d0638c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_list = (\n",
    "    None,\n",
    "    compose1,\n",
    "    compose2,\n",
    "    ...\n",
    ")\n",
    "\n",
    "len(aug_list) = 20! / (3! * (20-3)!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad3377-2c08-453e-bf54-e4609fab68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–æ–ª—É—á–∞–µ—Ç–µ —Ç–∞–∫—É—é —Ö—É–µ—Ç—É\n",
    "\n",
    "{\n",
    "    compose1: ({–ª–æ—Å—Å—ã}, 0.9999),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed768285-0755-4c22-8d60-d3746c7640e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "—Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç–µ —á–∏—Å–µ–ª–∫–∏ –∞–∫—å—é—Ä–∞—Å–∏—Å\n",
    "—Ä–∏—Å—É–µ—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ª–æ—Å–æ–≤ —Å –ø–æ–¥–ø–∏—Å–∫–æ–π –ª–µ–≥–µ–Ω–¥—ã –≥–¥–µ –∫–∞–∫–æ–π –∫–æ–º–ø–æ—É–∑\n",
    "\n",
    "–∑–Ω–∞—á–µ–Ω–∏–µ –ª–æ—Å—Å–∞ <> –Ω–æ–º–µ—Ä —ç–ø–æ—Ö–∏\n",
    "\n",
    "–µ—Å–ª–∏ —É—Å–ø–µ–µ—Ç–µ —Ç–æ –ø–æ —ç–ø–æ—Ö–∞–º —Å–¥–µ–ª–∞–µ—Ç–µ –∞–∫–∫—å—é—Ä–∞—Å–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31769c-3166-466f-85f9-a7833e8cce4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c6a4d5-0337-4421-8961-9a69a7119350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(aug1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05924d94-2364-462d-9566-d16192a2d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 2, 3, 4, 5, 6, 7, 8]\n",
    "[(...), (...)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52eef1-8675-4600-aa7f-32390e39b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[crop, RandomHorizontalFlip(p=0.5)] -> —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç–µ –ø–∞—Ä—ã, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç–µ –≤ –∫–æ–º–ø–æ—É–∑—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "603d082e-96b0-47d2-ab16-8595f363166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.__dir__();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b38be-8fcd-4594-8ea0-bc9160816a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
